#!/usr/bin/env python3
"""
Script principal pentru rularea scraper-ului de È™tiri financiare
"""
import os
import sys
import logging
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
from dotenv import load_dotenv

# ÃncarcÄƒ variabilele de mediu
load_dotenv()

def run_scrapy():
    """RuleazÄƒ spider-ul Scrapy pentru colectarea È™tirilor"""
    
    # ConfigureazÄƒ logging-ul
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(name)s] %(levelname)s: %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ Starting financial news scraper...")
    
    # VerificÄƒ dacÄƒ API key-ul OpenAI este disponibil
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        logger.warning("âš ï¸  OpenAI API key not found. AI analysis will be skipped.")
    else:
        logger.info("âœ… OpenAI API key found. AI analysis enabled.")
    
    # ConfigureazÄƒ È™i ruleazÄƒ procesul Scrapy
    settings = get_project_settings()
    process = CrawlerProcess(settings)
    
    # AdaugÄƒ spider-ul de È™tiri financiare
    process.crawl('financial_news')
    
    # RuleazÄƒ procesul
    try:
        process.start()
        logger.info("âœ… Scraping completed successfully!")
    except Exception as e:
        logger.error(f"âŒ Scraping failed: {str(e)}")
        sys.exit(1)

def main():
    """FuncÈ›ia principalÄƒ"""
    print("ğŸ¦ AIInvestorHood5 - Financial News Scraper")
    print("=" * 50)
    
    # SchimbÄƒ directorul de lucru la directorul scriptului
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    # RuleazÄƒ scraper-ul
    run_scrapy()

if __name__ == '__main__':
    main()